{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273b74cd-e826-4ced-97a7-ddaa07b0c151",
   "metadata": {},
   "source": [
    "# Autonomous Driving Object Detection and Recognition System.\n",
    "#### Using [yolov8](https://docs.ultralytics.com/models/yolov8/) object detection algorithms.\n",
    "#### Dataset from [bdd100k](https://doc.bdd100k.com/index.html).\n",
    "#### Author: Samir K C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f907a57d-9e5c-48e2-9adb-053929c8058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.20 | packaged by conda-forge | (main, Sep 30 2024, 17:48:00) \n",
      "[Clang 17.0.6 ]\n",
      "Python location: /Users/samirkc/micromamba/envs/yolov8-env/bin/python3.9\n",
      "PyTorch version: 2.5.1\n",
      "MPS (Apple Metal) available: True\n",
      "Current PyTorch device: mps\n",
      "OpenCV version: 4.10.0\n",
      "Ultralytics is installed.\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setting up my environment\n",
    "\n",
    "#Verify Python Environment\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python location: {sys.executable}\")\n",
    "\n",
    "# Verify PyTorch installation and MPS (Metal Performance Shaders) availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS (Apple Metal) available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"Current PyTorch device: {torch.device('mps' if torch.backends.mps.is_available() else 'cpu')}\")\n",
    "\n",
    "# Verify other essential packages\n",
    "import cv2\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "print(\"Ultralytics is installed.\")\n",
    "\n",
    "#Set default device for PyTorch\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7c5abd-0c4a-4777-b78c-7fcb4e9938f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_PATH = Path('./datasets/coco_splitted/') \n",
    "WEIGHTS_PATH = Path('./weights/')  # Path to save model weights\n",
    "RESULTS_PATH = Path('./results')  # Path to save results\n",
    "\n",
    "# Create necessary directories\n",
    "WEIGHTS_PATH.mkdir(exist_ok=True)\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a710269-6693-4ab4-b4b1-26528d73a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "params = {\n",
    "    # Data Parameters\n",
    "    'data_yaml': str(DATASET_PATH / 'data.yaml'),\n",
    "    'img_size': 320,         # Reduced image size for faster training\n",
    "    'batch_size': 4,        # Moderate batch size; increase if memory allows\n",
    "    \n",
    "    # Training Parameters\n",
    "    'epochs': 12,            # Cap epochs, or lower if accuracy is met early\n",
    "    'patience': 3,           # Early stopping patience for quicker training end\n",
    "    'model_type': 'yolov8n.pt', \n",
    "    'device': 'mps',         # Optimized for Apple M3 Pro\n",
    "\n",
    "    # Optimizer Parameters\n",
    "    'optimizer': 'auto',     # Let YOLOv8 auto-select the optimizer\n",
    "    'lr0': 0.01,             # Initial learning rate for efficient convergence\n",
    "    'lrf': 0.15,             # Higher learning rate decay for faster convergence\n",
    "    'momentum': 0.937,       # Momentum value\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 1.0,    # Reduced warmup for faster adaptation\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "\n",
    "    # Augmentation Parameters (disabled to save time)\n",
    "    # 'hsv_h': 0.015,\n",
    "    # 'hsv_s': 0.5,            # Slightly reduced saturation variation\n",
    "    # 'hsv_v': 0.2,            # Reduced brightness variation\n",
    "    # 'degrees': 0.0,\n",
    "    # 'translate': 0.1,\n",
    "    # 'scale': 0.5,\n",
    "    # 'shear': 0.0,\n",
    "    # 'flipud': 0.0,\n",
    "    # 'fliplr': 0.5,\n",
    "    # 'mosaic': 0.1,           # Lower mosaic probability to reduce training time\n",
    "    # 'mixup': 0.0,            # Disabled mixup to speed up training\n",
    "\n",
    "    # Other Parameters\n",
    "    'save_period': -1,       # Save checkpoint at the final epoch\n",
    "    'cache': False,          # Do not cache images to save memory\n",
    "    'half': True,            # Mixed precision for faster training\n",
    "    'accum': 2,              # Gradient accumulation to simulate larger batch size\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8afcc1-8b4a-4319-8551-bc7ad8a8ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train_model(params):\n",
    "    \"\"\"Train YOLOv8 model with ETA tracking and batch progress\"\"\"\n",
    "    # Load model\n",
    "    model = YOLO(params['model_type'])\n",
    "\n",
    "    total_epochs = params['epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    # Tracking overall training time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nStarting Epoch {epoch + 1}/{total_epochs}\")\n",
    "\n",
    "        # Adding tqdm for batch progress within the epoch\n",
    "        batch_progress = tqdm(\n",
    "            model.train(\n",
    "                data=params['data_yaml'],\n",
    "                imgsz=params['img_size'],\n",
    "                epochs=1,   # Run one epoch at a time to capture progress\n",
    "                batch=batch_size,\n",
    "                device=params['device'],\n",
    "                optimizer=params['optimizer'],\n",
    "                lr0=params['lr0'],\n",
    "                lrf=params['lrf'],\n",
    "                momentum=params['momentum'],\n",
    "                weight_decay=params['weight_decay'],\n",
    "                warmup_epochs=params['warmup_epochs'],\n",
    "                warmup_momentum=params['warmup_momentum'],\n",
    "                warmup_bias_lr=params['warmup_bias_lr'],\n",
    "                patience=params['patience'],\n",
    "                save_period=params['save_period'],\n",
    "                cache=params['cache'],\n",
    "                project=str(RESULTS_PATH),\n",
    "                name='train'\n",
    "            ),\n",
    "            desc=f\"Epoch {epoch + 1}/{total_epochs}\",\n",
    "            unit=\"batch\"\n",
    "        )\n",
    "\n",
    "        # Calculating time per epoch and estimated remaining time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_elapsed = time.time() - start_time\n",
    "        estimated_remaining = epoch_time * (total_epochs - (epoch + 1))\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{total_epochs} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"Estimated remaining time: {estimated_remaining // 60:.0f} min {estimated_remaining % 60:.0f} sec\")\n",
    "        print(f\"Total elapsed time: {total_elapsed // 60:.0f} min {total_elapsed % 60:.0f} sec\")\n",
    "        \n",
    "    # Return model and results after all epochs are done\n",
    "    total_training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining complete in {total_training_time // 60:.0f} min {total_training_time % 60:.0f} sec\")\n",
    "\n",
    "    return model, batch_progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02445aa3-5d07-41a1-87c5-7a316528a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "def evaluate_model(model):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    # Run validation on test set\n",
    "    metrics = model.val(data=params['data_yaml'])\n",
    "    \n",
    "    # Extract metrics\n",
    "    evaluation = {\n",
    "        'mAP50': metrics.box.map50,    # mAP at IoU=0.5\n",
    "        'mAP50-95': metrics.box.map,    # mAP at IoU=0.5:0.95\n",
    "        'precision': metrics.box.mp,     # mean precision\n",
    "        'recall': metrics.box.mr,        # mean recall\n",
    "        'f1-score': 2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr),\n",
    "        \n",
    "        # Per-class metrics\n",
    "        'per_class_mAP50': metrics.box.ap50_per_class,\n",
    "        'per_class_precision': metrics.box.p_per_class,\n",
    "        'per_class_recall': metrics.box.r_per_class\n",
    "    }\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Class': ['pedestrian', 'rider', 'car', 'truck', 'bus', 'train', \n",
    "                 'motorcycle', 'bicycle', 'traffic light', 'traffic sign'],\n",
    "        'mAP50': evaluation['per_class_mAP50'],\n",
    "        'Precision': evaluation['per_class_precision'],\n",
    "        'Recall': evaluation['per_class_recall']\n",
    "    })\n",
    "    \n",
    "    metrics_df.to_csv(RESULTS_PATH / 'class_metrics.csv', index=False)\n",
    "    \n",
    "    return evaluation, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c606c988-b3bb-4498-8956-68701179edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Results\n",
    "def analyze_results(evaluation, metrics_df):\n",
    "    \"\"\"Analyze and visualize evaluation results\"\"\"\n",
    "    # Print overall metrics\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"mAP50: {evaluation['mAP50']:.4f}\")\n",
    "    print(f\"mAP50-95: {evaluation['mAP50-95']:.4f}\")\n",
    "    print(f\"Precision: {evaluation['precision']:.4f}\")\n",
    "    print(f\"Recall: {evaluation['recall']:.4f}\")\n",
    "    print(f\"F1-Score: {evaluation['f1-score']:.4f}\")\n",
    "    \n",
    "    # Plot per-class metrics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_df.plot(x='Class', y=['mAP50', 'Precision', 'Recall'], kind='bar')\n",
    "    plt.title('Per-class Performance Metrics')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_PATH / 'class_performance.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e4863d-f73e-49d9-8dd5-002a93a09957",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main Execution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#model, results = train_model(params)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     evaluation, metrics_df \u001b[38;5;241m=\u001b[39m evaluate_model(\u001b[43mmodel\u001b[49m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Analyze results\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     analyze_results(evaluation, metrics_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Train model\n",
    "    #model, results = train_model(params)\n",
    "    model =     'yolov8n.pt', \n",
    "\n",
    "    # Evaluate model\n",
    "    evaluation, metrics_df = evaluate_model(model)\n",
    "    \n",
    "    # Analyze results\n",
    "    analyze_results(evaluation, metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e2c7a-59b0-44e7-82a5-5b682d2ff197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6ab29-5cf6-4e61-9e7d-c90faaf8d73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f672b-5f90-4e6d-a482-dd78f242c08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0f5b5-863b-42f1-b285-28b673af5f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a00a6-c287-4898-9872-00d7212e58f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d80d2-fd56-464c-a0e0-1a9530c06521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
